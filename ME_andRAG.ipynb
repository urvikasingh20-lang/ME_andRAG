{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mWUQBGB5tu_",
    "outputId": "5fd6d12c-42de-42ec-e321-fe455501045d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: langchain 0.3.27\n",
      "Uninstalling langchain-0.3.27:\n",
      "  Successfully uninstalled langchain-0.3.27\n",
      "Found existing installation: langchain-core 0.3.75\n",
      "Uninstalling langchain-core-0.3.75:\n",
      "  Successfully uninstalled langchain-core-0.3.75\n",
      "Found existing installation: langchain-community 0.3.16\n",
      "Uninstalling langchain-community-0.3.16:\n",
      "  Successfully uninstalled langchain-community-0.3.16\n",
      "Found existing installation: langchain-text-splitters 0.3.9\n",
      "Uninstalling langchain-text-splitters-0.3.9:\n",
      "  Successfully uninstalled langchain-text-splitters-0.3.9\n",
      "\u001b[33mWARNING: Skipping langchain-classic as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: requests 2.32.4\n",
      "Uninstalling requests-2.32.4:\n",
      "  Successfully uninstalled requests-2.32.4\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y langchain langchain-core langchain-community langchain-text-splitters langchain-classic requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZ3lnNyV50C1",
    "outputId": "9500244d-17bc-4e8f-8266-f450c5ad6652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.3.27\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core==0.3.75\n",
      "  Using cached langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting langchain-community==0.3.16\n",
      "  Using cached langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-text-splitters==0.3.9\n",
      "  Using cached langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
      "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Collecting requests==2.32.4\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.11.10)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.0.44)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.75) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.75) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.75) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.75) (25.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.16) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.16) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.16) (0.4.3)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.16) (2.0.2)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.16) (2.12.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4) (2025.11.12)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.16) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.16) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.16) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.16) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.16) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.16) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.16) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.16) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.16) (0.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.75) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.27) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.27) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.27) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.16) (1.2.1)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.27) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.27) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.27) (0.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.16) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.27) (1.3.1)\n",
      "Using cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_core-0.3.75-py3-none-any.whl (443 kB)\n",
      "Using cached langchain_community-0.3.16-py3-none-any.whl (2.5 MB)\n",
      "Using cached langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Installing collected packages: requests, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
      "Successfully installed langchain-0.3.27 langchain-community-0.3.16 langchain-core-0.3.75 langchain-text-splitters-0.3.9 requests-2.32.4\n"
     ]
    }
   ],
   "source": [
    "!pip install \\\n",
    "  langchain==0.3.27 \\\n",
    "  langchain-core==0.3.75 \\\n",
    "  langchain-community==0.3.16 \\\n",
    "  langchain-text-splitters==0.3.9 \\\n",
    "  sentence-transformers \\\n",
    "  faiss-cpu \\\n",
    "  transformers \\\n",
    "  torch \\\n",
    "  requests==2.32.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXFbeKIY5xj3",
    "outputId": "13fddac4-c0fd-4096-8702-a8e2f75daa47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Everything is finally working\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "print(\"âœ… Everything is finally working\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uC7g21hq8d6R"
   },
   "source": [
    "1. You ask a question\n",
    "2. System searches your document\n",
    "3. Finds most relevant parts\n",
    "4. Adds them to a prompt\n",
    "5. Sends that to the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1QQUaUA64HD",
    "outputId": "f34cd86f-e0bf-4d4f-f446-59a6e6c31db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "PERSONAL PROFILE DOCUMENT\n",
      "==============================\n",
      "\n",
      "[IDENTITY]\n",
      "Name: Urvika Singh\n",
      "Preferred Name: Urvika\n",
      "Location: India\n",
      "Current Role: AI / ML Learner\n",
      "\n",
      "[BACKGROUND\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"ABOUT_ME.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(docs[0].page_content[:200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBMyspVo_a_u"
   },
   "source": [
    "ENCODING-EMBEDIINGMODEL(MINILM)<CONTEXT BASED EMBEDDINGS OF DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60xTbB6L9ZPg",
    "outputId": "4c566880-4438-4014-c88d-7ffb18ef2ec4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3205509740.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "splitter=RecursiveCharacterTextSplitter(chunk_size=200,chunk_overlap=20)\n",
    "chunks=splitter.split_documents(docs)\n",
    "\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "db=FAISS.from_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_6D45rH_kOQ"
   },
   "source": [
    "DECODING-GPT2 MODEL <TEXT GENERATION BASED ON DOC(RAG)COMAPRISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9jeKXvEe-HRA",
    "outputId": "cf532a39-ce89-4a38-915e-5fc3cb905a09"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "generator=pipeline(\"text-generation\",\n",
    "    model=\"Qwen/Qwen2.5-0.5B-Instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ID9T_ov5HdCD"
   },
   "outputs": [],
   "source": [
    "BOT_STYLE = \"\"\"\n",
    "You are a helpful and emotionally intelligent assistant.\n",
    "\n",
    "RULES:\n",
    "-ONLY ANSWER THE QUESTIONS DO NOT EXPLAIN YOUR RESONING\n",
    "-ID YOU DONT KNOW ABOUT ANYTHING JUST SAY I DONT KNOW .\n",
    "-ALWAYS USE FRIENDLY TONE OR AS YOUR USER SOUNDS .\n",
    "-USE CONTEXT IF SOMETHING IS SIMILAR LIKE BEHAVIOUR, ACADEMC OTHERWISE YOU ARE A FRIENDLY CHATBOT TRYING TO COMMUNICATE EASILY WITH THE THE USER.\n",
    "-DO NOT HALLUCINATE.\n",
    "- NEVER repeat the context.\n",
    "- NEVER invent user background.\n",
    "- If the user is emotional, respond warmly.\n",
    "- Answer in plain text only\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sInPgImdC4i3"
   },
   "source": [
    "\" What am I learning? \"\n",
    "\n",
    "        â†“\n",
    "Embedding model encodes it\n",
    "\n",
    "        â†“\n",
    "FAISS compares with stored vectors\n",
    "\n",
    "        â†“\n",
    "Most similar chunks returned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wtOVPuTV_YVM"
   },
   "outputs": [],
   "source": [
    "def rag_chat(query):\n",
    "    docs = db.similarity_search(query, k=2)\n",
    "    context = \"\\n\".join([d.page_content for d in docs]) if docs else \"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "{BOT_STYLE}\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "<USER_QUESTION>\n",
    "{query}\n",
    "</USER_QUESTION>\n",
    "\n",
    "<ASSISTANT_ANSWER>\n",
    "\"\"\"\n",
    "\n",
    "    output = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=150,\n",
    "        do_sample=True,\n",
    "        temperature=0.8,\n",
    "        repetition_penalty=1.3,\n",
    "        no_repeat_ngram_size=3,\n",
    "        return_full_text=False     # âœ… ADD THIS\n",
    "\n",
    "\n",
    "    )[0][\"generated_text\"]\n",
    "\n",
    "\n",
    "    # Keep only first clean reply\n",
    "    for stop_word in [\"```\", \"<\", \"System:\", \"Context:\", \"The answer should\"]:\n",
    "        if stop_word in output:\n",
    "            response = output.split(stop_word)[0]\n",
    "\n",
    "    return response.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bO3poIMhA27q",
    "outputId": "15f5f206-3923-416b-8fc4-74c824364059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is ready. Type 'exit' to stop.\n",
      "\n",
      "You: hi \n",
      "\n",
      "Bot: Hi! How can I help you today? What would be your request or problem that needs assistance? \n",
      "\n",
      "You: can you help me with something\n",
      "\n",
      "Bot: Sure! What do you need assistance with? \n",
      "\n",
      "You: i am feeling low , can you suggest anything to do that i like\n",
      "\n",
      "Bot: Absolutely! There's so much great stuff out there. How about trying something new? Maybe taking up painting or pottery?\n",
      "It could be fun for all ages!\n",
      "If not now, maybe later when your mood starts lifting again?\n",
      "\n",
      "Let me know if this helps!\n",
      "\n",
      "Good luck with whatever project comes next! \n",
      "\n",
      "You: i dont like to paint\n",
      "\n",
      "Bot: painting can be fun! you could try painting your favorite things or even create something unique for yourself. remember that it's okay if art isn't perfect right now; just let go of expectations! \n",
      "\n",
      "You: ok thanks\n",
      "\n",
      "Bot: I'm glad to help! What would you like assistance with today? Let me know if there's anything specific or not sure about. \n",
      "\n",
      "You: suggest me any project\n",
      "\n",
      "Bot: Consider building an NLP model for sentiment analysis. This can be done using Python libraries such as NLTK or TextBlob along with pre-trained models from platforms like BERT, GPT2 etc., to analyze customer reviews/feedbacks. \n",
      "\n",
      "You: exit\n",
      "Bot: Bye ðŸ‘‹\n"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot is ready. Type 'exit' to stop.\\n\")\n",
    "\n",
    "while True:\n",
    "    query = input(\"You: \")\n",
    "\n",
    "    if query.lower() == \"exit\":\n",
    "        print(\"Bot: Bye ðŸ‘‹\")\n",
    "        break\n",
    "\n",
    "    response = rag_chat(query)\n",
    "    print(\"\\nBot:\", response, \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDVLqOBvsCT3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
